======================================================================
MULTINOMIAL NAIVE BAYES EXPERIMENT
======================================================================
Loading data from ../data/raw/sentiment_data.csv...
Successfully read CSV with encoding: utf-8
Dataset shape: (241145, 2)
Sentiment distribution:
sentiment
2    103059
1     82972
0     55114
Name: count, dtype: int64

Applying basic cleaning for Bayes Model...
Applying basic cleaning for Bayes Model...
Train set: 144687 samples
Validation set: 48229 samples
Test set: 48229 samples


Running GridSearchCV with 5-fold. cross-validation...
Total parameter combinations to test: 96
Fitting 5 folds for each of 96 candidates, totalling 480 fits
Train set: 144687 samples
Validation set: 48229 samples
Test set: 48229 samples


Running GridSearchCV with 5-fold. cross-validation...
Total parameter combinations to test: 96
Fitting 5 folds for each of 96 candidates, totalling 480 fits

Best hyperparameters: {'classifier__alpha': 1.0, 'vectorizer__max_df': 0.85, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 1)}
Best cross-validation accuracy: 0.6700

Best hyperparameters: {'classifier__alpha': 1.0, 'vectorizer__max_df': 0.85, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 10, 'vectorizer__ngram_range': (1, 1)}
Best cross-validation accuracy: 0.6700

Validation Accuracy: 0.6731

Validation Classification Report:
              precision    recall  f1-score   support

           0       0.64      0.63      0.64     11023
           1       0.67      0.61      0.64     16594
           2       0.69      0.75      0.72     20612

    accuracy                           0.67     48229
   macro avg       0.67      0.66      0.66     48229
weighted avg       0.67      0.67      0.67     48229


======================================================================
FINAL TEST SET EVALUATION - Multinomial Naive Bayes
======================================================================

Validation Accuracy: 0.6731

Validation Classification Report:
              precision    recall  f1-score   support

           0       0.64      0.63      0.64     11023
           1       0.67      0.61      0.64     16594
           2       0.69      0.75      0.72     20612

    accuracy                           0.67     48229
   macro avg       0.67      0.66      0.66     48229
weighted avg       0.67      0.67      0.67     48229


======================================================================
FINAL TEST SET EVALUATION - Multinomial Naive Bayes
======================================================================

Final Test Accuracy: 0.6699 (66.99%)

Classification Report:
              precision    recall  f1-score   support

           0       0.64      0.62      0.63     11023
           1       0.66      0.61      0.63     16594
           2       0.69      0.75      0.72     20612

    accuracy                           0.67     48229
   macro avg       0.66      0.66      0.66     48229
weighted avg       0.67      0.67      0.67     48229


======================================================================
DETAILED ANALYSIS - Multinomial Naive Bayes
======================================================================

Final Test Accuracy: 0.6699 (66.99%)

Classification Report:
              precision    recall  f1-score   support

           0       0.64      0.62      0.63     11023
           1       0.66      0.61      0.63     16594
           2       0.69      0.75      0.72     20612

    accuracy                           0.67     48229
   macro avg       0.66      0.66      0.66     48229
weighted avg       0.67      0.67      0.67     48229


======================================================================
DETAILED ANALYSIS - Multinomial Naive Bayes
======================================================================

Confusion Matrix:
                Predicted
              Neg  Neu  Pos
Actual Neg    6863 2059 2101
       Neu    1791 10092 4711
       Pos    2141 3115 15356

Per-Class Accuracy:
Negative  : 0.6226 (62.26%)
Neutral   : 0.6082 (60.82%)
Positive  : 0.7450 (74.50%)

======================================================================
SAMPLE PREDICTIONS - Multinomial Naive Bayes
======================================================================
Text: 'This is an amazing product, I love it!'
Predicted: Positive (2)

Text: 'I really hate this, it's the worst thing ever.'
Predicted: Negative (0)

Text: 'The package arrived today.'
Predicted: Neutral (1)

Text: 'Absolutely fantastic experience, highly recommend!'
Predicted: Positive (2)

Text: 'Terrible quality, very disappointed.'
Predicted: Negative (0)

Text: 'It's okay, nothing special but not bad either.'
Predicted: Positive (2)

Text: 'Best purchase ever! Worth every penny!'
Predicted: Positive (2)

Text: 'Complete waste of money, horrible experience.'
Predicted: Negative (0)

Text: 'The product works as expected.'
Predicted: Positive (2)

Text: 'Meh, it's alright I guess.'
Predicted: Neutral (1)


Confusion Matrix:
                Predicted
              Neg  Neu  Pos
Actual Neg    6863 2059 2101
       Neu    1791 10092 4711
       Pos    2141 3115 15356

Per-Class Accuracy:
Negative  : 0.6226 (62.26%)
Neutral   : 0.6082 (60.82%)
Positive  : 0.7450 (74.50%)

======================================================================
SAMPLE PREDICTIONS - Multinomial Naive Bayes
======================================================================
Text: 'This is an amazing product, I love it!'
Predicted: Positive (2)

Text: 'I really hate this, it's the worst thing ever.'
Predicted: Negative (0)

Text: 'The package arrived today.'
Predicted: Neutral (1)

Text: 'Absolutely fantastic experience, highly recommend!'
Predicted: Positive (2)

Text: 'Terrible quality, very disappointed.'
Predicted: Negative (0)

Text: 'It's okay, nothing special but not bad either.'
Predicted: Positive (2)

Text: 'Best purchase ever! Worth every penny!'
Predicted: Positive (2)

Text: 'Complete waste of money, horrible experience.'
Predicted: Negative (0)

Text: 'The product works as expected.'
Predicted: Positive (2)

Text: 'Meh, it's alright I guess.'
Predicted: Neutral (1)